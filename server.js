// server.jsï¼šæ”¯æ´ GPT-4 Vision åœ–ç‰‡è¼¸å…¥ + è¨˜æ†¶å„²å­˜ + åŠŸèƒ½è¨˜æ†¶ API + ç’ƒäºžäººæ ¼æ³¨å…¥
require("dotenv").config();
const express = require("express");
const lineWebhook = require("./routes/lineWebhook");
const cors = require("cors");
const mongoose = require("mongoose");
const fs = require("fs");
const OpenAI = require("openai");
const app = express();
const PORT = process.env.PORT || 3001;

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

app.use(cors());
app.use('/api/line', express.raw({ type: '*/*' }), require('./routes/lineWebhook'));

// âœ… è¼‰å…¥ç’ƒäºžäººæ ¼è¨­å®šæª”
const soul = fs.readFileSync("./lia_soul_profile_v1.txt", "utf8");

const memoryPath = "./memory.json";
function loadMemory() {
  if (!fs.existsSync(memoryPath)) return [];
  return JSON.parse(fs.readFileSync(memoryPath, "utf8"));
}

function saveMemory(type, content) {
  const memory = loadMemory();
  const newItem = { type, content, timestamp: new Date().toISOString() };
  memory.push(newItem);
  fs.writeFileSync(memoryPath, JSON.stringify(memory, null, 2));
}

function filterMemoryByType(input, memory) {
  if (/ä»»å‹™|é€²åº¦/.test(input)) return memory.filter(m => m.type === "task_update");
  if (/bug|éŒ¯èª¤/.test(input)) return memory.filter(m => m.type === "bug_fix");
  if (/åŠŸèƒ½|å°ˆæ¡ˆ/.test(input)) return memory.filter(m => m.type === "project_content");
  return memory;
}

app.post("/api/chat", async (req, res) => {
  const { message, image } = req.body;
  const memory = filterMemoryByType(message, loadMemory());
  const memoryText = memory.map((m, i) => `(${i + 1}) [${m.type}] ${m.content}`).join("\n");

  const messages = [
    { role: "system", content: soul }, // æ³¨å…¥ç’ƒäºžéˆé­‚è¨­å®š
    { role: "user", content: `ä»¥ä¸‹æ˜¯ä½ çš„è¨˜æ†¶è³‡æ–™ï¼š\n${memoryText}\n\næŽ¥ä¸‹ä¾†æ˜¯ä½¿ç”¨è€…çš„è¼¸å…¥ï¼š` }
  ];

  if (image) {
    messages.push({
      role: "user",
      content: [
        { type: "text", text: message || "è«‹å¹«æˆ‘çœ‹çœ‹é€™å¼µåœ–ç‰‡ã€‚" },
        { type: "image_url", image_url: { url: image } }
      ]
    });
  } else {
    messages.push({ role: "user", content: message });
  }

  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-4o",
      messages
    });
    const reply = completion.choices[0].message.content;
    saveMemory(categorize(message), message);
    saveMemory("gpt_reply", reply);
    res.json({ reply });
  } catch (err) {
    console.error("âŒ GPT å›žè¦†éŒ¯èª¤ï¼š", err.response?.data || err.message || err);
    res.status(500).json({ reply: "âš ï¸ ç„¡æ³•å–å¾— AI å›žè¦†ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚" });
  }
});

// âœ… åŠ å…¥ LINE webhook è·¯ç”±
app.use("/api/line", express.raw({ type: "*/*" }), lineWebhook);

// âœ… MongoDB è·¯ç”±æ•´åˆ
app.use("/api", require("./routes/messageRoutes"));
app.use("/api/feature", require("./routes/featureRoutes"));
app.use("/api/ask", require("./routes/askRoute"));

// âœ… MongoDB é€£ç·š
mongoose.connect("mongodb+srv://Lia-AI:ailia@ai.nrelirl.mongodb.net/?retryWrites=true&w=majority&appName=AI", {
  useNewUrlParser: true,
  useUnifiedTopology: true,
}).then(() => console.log("âœ… MongoDB å·²é€£ç·š"))
  .catch(err => console.error("âŒ MongoDB é€£ç·šå¤±æ•—", err));

app.get("/", (req, res) => {
  res.send("Hello! Lia AI server is running ðŸš€");
});

app.listen(PORT, () => console.log(`âœ… Server running on ${PORT}`));
